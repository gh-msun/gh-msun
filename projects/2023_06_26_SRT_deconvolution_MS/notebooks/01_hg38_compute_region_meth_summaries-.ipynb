{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Frag Meth Summaries for a Region Set\n",
    "\n",
    "Given a region set will compute frag scores for all samples in PAT Parquet files. Here we use hg38 PARQUET files.\n",
    "\n",
    "SET UP SDDs TO BE USED WITH SPARK PRIOR TO RUNNING THIS NOTEBOOK!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = 'deconvolution_v2.v23_conv.with_cpg_index'\n",
    "REGION_BED_COLS = [\n",
    "    'region_chr', 'region_start', 'region_end', \n",
    "    'region_cpg_index_min', 'region_cpg_index_max', 'region_id'\n",
    "]\n",
    "FILTER_CG_COUNT = 3\n",
    "FILTER_CG_COUNT_REGION = 1\n",
    "\n",
    "#--- Local paths\n",
    "ROOT_DIR = '/analysis/gh-msun/projects'\n",
    "PROJECT_SLUG = '2023_06_26_SRT_deconvolution_MS'\n",
    "PROJECT_DIR = ROOT_DIR + '/{}'.format(PROJECT_SLUG)\n",
    "\n",
    "# Regions\n",
    "REGION_PATH = (\n",
    "    PROJECT_DIR + '/stage/panel_data/{regions}.bed'\n",
    ").format(regions=REGIONS)\n",
    "\n",
    "# CpG map; genomic coordinate to CpG index;\n",
    "CPG_MAP_PATH = PROJECT_DIR + '/stage/cpg_loci/cpg_loci_hg19.combined_annot.tsv.gz'\n",
    "\n",
    "\n",
    "# BLUEPRINT HG38: s3://gh-bi-lunar/public_data/blueprint/hg38_20160816.pat.db_version.parquet/\n",
    "PARQUET_PATH_LIST_HG38 = [\n",
    "    '/analysis/hg38_20160816.pat.db_version.parquet'\n",
    "]\n",
    "\n",
    "#--- Where to store results\n",
    "RESULTS_PATH = (\n",
    "    PROJECT_DIR + '/output/meth_summaries/blueprint_meth_summaries_cg_count_geq_{k}_{regions}.tsv.gz'\n",
    ").format(regions=REGIONS, k=FILTER_CG_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/meth_summaries/blueprint_meth_summaries_cg_count_geq_3_deconvolution_v2.v23_conv.with_cpg_index.tsv.gz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "## this works for PySpark v3.3.1 - only need to run this once\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages {aws_java},{aws_hadoop} pyspark-shell\".\\\n",
    "   format(aws_java=\"com.amazonaws:aws-java-sdk-bundle:1.11.271\",\n",
    "          aws_hadoop=\"org.apache.hadoop:hadoop-aws:3.1.2\")\n",
    "#####\n",
    "\n",
    "# UPDATE HOME!\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark\"\n",
    "# THIS needs to be set-up before running the notebook\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CpG Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_map = pd.read_csv(CPG_MAP_PATH, usecols=['chr', 'start', 'end', 'cpg_index', 'cpg_index_hg38'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 5.54 s, total: 20.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridxs = ~cpg_map['cpg_index_hg38'].isna()\n",
    "hg19_hg38_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index'], cpg_map[ridxs]['cpg_index_hg38'].astype(int)))\n",
    "hg38_hg19_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index_hg38'].astype(int), cpg_map[ridxs]['cpg_index']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df = pd.read_csv(REGION_PATH, sep='\\t', usecols=range(0, 6), names=REGION_BED_COLS)\n",
    "\n",
    "region_df['region_cpg_index_max'] -= 1\n",
    "region_df.sort_values('region_cpg_index_min', inplace=True)\n",
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min'].map(hg19_hg38_map)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max'].map(hg19_hg38_map)\n",
    "\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_chr</th>\n",
       "      <th>region_start</th>\n",
       "      <th>region_end</th>\n",
       "      <th>region_cpg_index_min</th>\n",
       "      <th>region_cpg_index_max</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_cpg_index_min_hg38</th>\n",
       "      <th>region_cpg_index_max_hg38</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1114771</td>\n",
       "      <td>1114971</td>\n",
       "      <td>20117</td>\n",
       "      <td>20129</td>\n",
       "      <td>Immune_Broad_B-chr1:1114772-1114971</td>\n",
       "      <td>21119</td>\n",
       "      <td>21131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157450</td>\n",
       "      <td>1157720</td>\n",
       "      <td>21684</td>\n",
       "      <td>21703</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157451-1157720</td>\n",
       "      <td>22686</td>\n",
       "      <td>22705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157879</td>\n",
       "      <td>1158277</td>\n",
       "      <td>21710</td>\n",
       "      <td>21726</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157880-1158277</td>\n",
       "      <td>22712</td>\n",
       "      <td>22728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1652503</td>\n",
       "      <td>1652793</td>\n",
       "      <td>41590</td>\n",
       "      <td>41598</td>\n",
       "      <td>Loyfer2022_Preprint_Colon-Ep:Gastric-Ep:Small-...</td>\n",
       "      <td>42716</td>\n",
       "      <td>42724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1849567</td>\n",
       "      <td>1849674</td>\n",
       "      <td>46692</td>\n",
       "      <td>46697</td>\n",
       "      <td>Pancreas_Acinar-chr1:1849568-1849674</td>\n",
       "      <td>47819</td>\n",
       "      <td>47824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region_chr  region_start  region_end  region_cpg_index_min  region_cpg_index_max                                          region_id  region_cpg_index_min_hg38  region_cpg_index_max_hg38  batch\n",
       "0       chr1       1114771     1114971                 20117                 20129                Immune_Broad_B-chr1:1114772-1114971                      21119                      21131      0\n",
       "1       chr1       1157450     1157720                 21684                 21703               Immune_Broad_NK-chr1:1157451-1157720                      22686                      22705      0\n",
       "2       chr1       1157879     1158277                 21710                 21726               Immune_Broad_NK-chr1:1157880-1158277                      22712                      22728      0\n",
       "3       chr1       1652503     1652793                 41590                 41598  Loyfer2022_Preprint_Colon-Ep:Gastric-Ep:Small-...                      42716                      42724      0\n",
       "4       chr1       1849567     1849674                 46692                 46697               Pancreas_Acinar-chr1:1849568-1849674                      47819                      47824      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridxs = ~region_df['region_cpg_index_min_hg38'].isna()\n",
    "ridxs &= ~region_df['region_cpg_index_max_hg38'].isna()\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 1657)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg_count_hg19 = region_df['region_cpg_index_max']-region_df['region_cpg_index_min'] + 1\n",
    "cg_count_hg38 = region_df['region_cpg_index_max_hg38']-region_df['region_cpg_index_min_hg38'] + 1\n",
    "ridxs = (cg_count_hg19==cg_count_hg38)\n",
    "ridxs &= (cg_count_hg19>=FILTER_CG_COUNT_REGION)\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min_hg38'].astype(int)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max_hg38'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAT PARQUET Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_COLS = [\n",
    "    'sample_id', 'molecule_id', 'chr', 'number_molecules',\n",
    "    'cpg_index_min', 'cpg_index_max', 'pat_string'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sample_id: string (nullable = true)\n",
      " |-- molecule_id: string (nullable = true)\n",
      " |-- chr: string (nullable = true)\n",
      " |-- number_molecules: integer (nullable = true)\n",
      " |-- cpg_index_min: long (nullable = true)\n",
      " |-- cpg_index_max: long (nullable = true)\n",
      " |-- pat_string: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat_parquet_files = [spark.read.parquet(ifile).select(*PAT_COLS) for ifile in PARQUET_PATH_LIST_HG38]\n",
    "pat_hg38_ddf = functools.reduce(DataFrame.unionByName, pat_parquet_files)\n",
    "pat_hg38_ddf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "|sample_id|molecule_id| chr|number_molecules|cpg_index_min|cpg_index_max|          pat_string|\n",
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "|ERS337091|          2|chr1|               1|           17|           57|TTCTCCTTTCCCCCTTC...|\n",
      "|ERS337091|          1|chr1|               1|           19|           58|TTCCCCCTTCTCCTTTC...|\n",
      "|ERS337091|          3|chr1|               1|           99|          115|   CCCCCCCCCCCCCCCTT|\n",
      "|ERS337091|          6|chr1|               1|          101|          120|CCTCCCCCCCC....TTCTT|\n",
      "|ERS337091|          5|chr1|               1|          108|          118|         CCCCCCTCCTC|\n",
      "|ERS337091|          4|chr1|               1|          110|          118|           CCCTTTCTC|\n",
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat_hg38_ddf.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sample_id = pat_hg38_ddf.select('sample_id').distinct().collect()  \n",
    "len(unique_sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute median fragment count per sample: 297,233,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|sample_id|    count|\n",
      "+---------+---------+\n",
      "|ERS568736| 17780129|\n",
      "|ERS392586| 55655580|\n",
      "|ERS392582| 58590887|\n",
      "|ERS392584| 61896835|\n",
      "|ERS392580| 64465551|\n",
      "|ERS661058|163079538|\n",
      "+---------+---------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_count_by_sample = pat_hg38_ddf.groupBy('sample_id').count().orderBy('count')\n",
    "read_count_by_sample.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.270000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.425187e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.465979e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.778013e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.790946e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.972331e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.957775e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.057485e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count  1.270000e+02\n",
       "mean   3.425187e+08\n",
       "std    1.465979e+08\n",
       "min    1.778013e+07\n",
       "25%    2.790946e+08\n",
       "50%    2.972331e+08\n",
       "75%    3.957775e+08\n",
       "max    1.057485e+09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_count_by_sample = read_count_by_sample.toPandas()\n",
    "df_read_count_by_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43499869385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_count_by_sample['count'].sum()\n",
    "# total count: 43,499,869,385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragment Level Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTILES = [0.1, 0.25, 0.75, 0.9]\n",
    "KMERS = [1, 3, 4]\n",
    "RATES_LEQ = [0.25]\n",
    "RATES_GEQ = [0.75]\n",
    "\n",
    "RETURN_SCHEMA = StructType()\\\n",
    "    .add('sample_id', 'string')\\\n",
    "    .add('region_id', 'string')\\\n",
    "    .add('number_molecules', 'integer')\\\n",
    "    .add('meth_k1', 'integer')\\\n",
    "    .add('unmeth_k1', 'integer')\\\n",
    "    .add('total_k1', 'integer')\\\n",
    "    .add('meth_k3', 'integer')\\\n",
    "    .add('unmeth_k3', 'integer')\\\n",
    "    .add('total_k3', 'integer')\\\n",
    "    .add('meth_k4', 'integer')\\\n",
    "    .add('unmeth_k4', 'integer')\\\n",
    "    .add('total_k4', 'integer')\\\n",
    "    .add('frac_alpha_leq_25pct', 'float')\\\n",
    "    .add('frac_alpha_geq_75pct', 'float')\n",
    "\n",
    "def compute_frag_scores(cpg_number_cutoff: int) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns a function, used for reduce\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_frag_scores_inner(pat_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        data = pat_df.copy()\n",
    "        data['offset_min'] = (data['region_cpg_index_min'] - data['cpg_index_min']).clip(lower=0)\n",
    "        data['offset_max'] = np.minimum(\n",
    "            data['region_cpg_index_max'] - data['cpg_index_min'], \n",
    "            data['cpg_index_max'] - data['cpg_index_min'])\n",
    "        data['trimmed_pat'] = data.apply(lambda x: x['pat_string'][x['offset_min']:(x['offset_max']+1)], axis=1)\n",
    "        #--- Filter molecules based on observed CpG loci\n",
    "        observed_cpg_number = (data['trimmed_pat'].str.count('C')+data['trimmed_pat'].str.count('T'))\n",
    "        ridxs = (observed_cpg_number>=cpg_number_cutoff)\n",
    "        data = data[ridxs].copy()\n",
    "        if (data.shape[0]>0):\n",
    "            # Compute k-mer methylation states\n",
    "            for k in KMERS:\n",
    "                data['meth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[C]{%i}'%k, x, overlapped=True)))\n",
    "                data['unmeth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[T]{%i}'%k, x, overlapped=True)))\n",
    "                data['total_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[TC]{%i}'%k, x, overlapped=True)))\n",
    "            # Compute alpha distribution metrics\n",
    "            data['alpha'] = data['meth_k1']/data['total_k1']\n",
    "            for rate in RATES_LEQ:\n",
    "                data['frac_alpha_leq_%ipct'%(100*rate)] = np.where(data['alpha']<=rate, 1, 0)\n",
    "            for rate in RATES_GEQ:\n",
    "                data['frac_alpha_geq_%ipct'%(100*rate)] = np.where(data['alpha']>=rate, 1, 0)\n",
    "            # Expand entries that correspond to multiple molecules\n",
    "            data['number_molecules'] = data['number_molecules'].apply(lambda x: list(range(x)))\n",
    "            data = data.explode('number_molecules')\n",
    "            data['number_molecules'] = 1\n",
    "            # Aggregate metrics\n",
    "            rv = data.groupby(['region_id', 'sample_id'])\\\n",
    "                [['meth_k1', 'unmeth_k1', 'total_k1',\n",
    "                  'meth_k3', 'unmeth_k3', 'total_k3',\n",
    "                  'meth_k4', 'unmeth_k4', 'total_k4',\n",
    "                  'frac_alpha_leq_25pct', 'frac_alpha_geq_75pct', 'number_molecules']].sum()\\\n",
    "                .reset_index()\n",
    "            rv['frac_alpha_leq_25pct'] = rv['frac_alpha_leq_25pct']/rv['number_molecules']\n",
    "            rv['frac_alpha_geq_75pct'] = rv['frac_alpha_geq_75pct']/rv['number_molecules']\n",
    "        else:\n",
    "            rv = pd.DataFrame(columns=RETURN_SCHEMA.names)\n",
    "                      \n",
    "        \n",
    "        return rv[RETURN_SCHEMA.names]\n",
    "\n",
    "    return compute_frag_scores_inner\n",
    "\n",
    "\n",
    "compute_frag_scores_udf = compute_frag_scores(cpg_number_cutoff=FILTER_CG_COUNT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for HG38 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 0...\n",
      "---> Processing batch 1...\n",
      "---> Processing batch 2...\n",
      "---> Processing batch 3...\n",
      "---> Processing batch 4...\n",
      "---> Processing batch 5...\n",
      "---> Processing batch 6...\n",
      "---> Processing batch 7...\n",
      "---> Processing batch 8...\n",
      "---> Processing batch 9...\n",
      "---> Processing batch 10...\n",
      "---> Processing batch 11...\n",
      "---> Processing batch 12...\n",
      "---> Processing batch 13...\n",
      "---> Processing batch 14...\n",
      "---> Processing batch 15...\n",
      "---> Processing batch 16...\n",
      "---> Processing batch 17...\n",
      "---> Processing batch 18...\n",
      "---> Processing batch 19...\n",
      "---> Processing batch 22...\n",
      "---> Processing batch 23...\n",
      "---> Processing batch 24...\n",
      "---> Processing batch 25...\n",
      "---> Processing batch 26...\n",
      "---> Processing batch 27...\n",
      "---> Processing batch 28...\n",
      "---> Processing batch 29...\n",
      "---> Processing batch 30...\n",
      "---> Processing batch 31...\n",
      "---> Processing batch 32...\n",
      "---> Processing batch 33...\n",
      "---> Processing batch 34...\n",
      "---> Processing batch 35...\n",
      "---> Processing batch 36...\n",
      "---> Processing batch 37...\n",
      "---> Processing batch 38...\n",
      "---> Processing batch 39...\n",
      "---> Processing batch 40...\n",
      "---> Processing batch 41...\n",
      "---> Processing batch 42...\n",
      "---> Processing batch 43...\n",
      "---> Processing batch 44...\n",
      "---> Processing batch 45...\n",
      "---> Processing batch 46...\n",
      "---> Processing batch 47...\n",
      "---> Processing batch 48...\n",
      "---> Processing batch 49...\n",
      "---> Processing batch 50...\n",
      "---> Processing batch 51...\n",
      "---> Processing batch 52...\n",
      "---> Processing batch 53...\n",
      "---> Processing batch 54...\n",
      "---> Processing batch 55...\n",
      "---> Processing batch 56...\n",
      "---> Processing batch 57...\n",
      "---> Processing batch 58...\n",
      "---> Processing batch 59...\n",
      "---> Processing batch 60...\n",
      "---> Processing batch 61...\n",
      "---> Processing batch 62...\n",
      "---> Processing batch 63...\n",
      "---> Processing batch 65...\n",
      "---> Processing batch 66...\n",
      "---> Processing batch 67...\n",
      "---> Processing batch 68...\n",
      "---> Processing batch 69...\n",
      "---> Processing batch 70...\n",
      "---> Processing batch 71...\n",
      "---> Processing batch 72...\n",
      "---> Processing batch 73...\n",
      "---> Processing batch 74...\n",
      "---> Processing batch 75...\n",
      "---> Processing batch 76...\n",
      "---> Processing batch 77...\n",
      "---> Processing batch 78...\n",
      "---> Processing batch 79...\n",
      "---> Processing batch 80...\n",
      "---> Processing batch 81...\n",
      "---> Processing batch 82...\n",
      "CPU times: user 6.04 s, sys: 965 ms, total: 7 s\n",
      "Wall time: 1h 46min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 20\n",
    "region_df['batch'] = (np.arange(region_df.shape[0])/BATCH_SIZE).astype(int)\n",
    "rv_scores = list()\n",
    "for batch, batch_region_df in region_df.groupby('batch'):\n",
    "    rv_ov = list()\n",
    "    print('---> Processing batch %i...' % batch)\n",
    "    for _, row in batch_region_df.iterrows():\n",
    "        ov_ddf = pat_hg38_ddf.filter(col('cpg_index_min')<=row['region_cpg_index_max_hg38'])\\\n",
    "            .filter(col('cpg_index_max') >= row['region_cpg_index_min_hg38'])\\\n",
    "            .withColumn('region_id', lit(row['region_id']))\\\n",
    "            .withColumn('region_cpg_index_min', lit(row['region_cpg_index_min_hg38']))\\\n",
    "            .withColumn('region_cpg_index_max', lit(row['region_cpg_index_max_hg38']))\n",
    "        rv_ov.append(ov_ddf)\n",
    "    scores_df = functools.reduce(DataFrame.union, rv_ov)\\\n",
    "        .groupby('region_id')\\\n",
    "        .applyInPandas(compute_frag_scores_udf, schema=RETURN_SCHEMA)\\\n",
    "        .toPandas()\n",
    "    rv_scores.append(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_hg38_df = pd.concat(rv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206303, 1648, 127)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = scores_hg38_df\n",
    "scores_df.shape[0], scores_df['region_id'].nunique(), scores_df['sample_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 2.43 ms, total: 3.11 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores_df.to_csv(RESULTS_PATH,\n",
    "                 sep='\\t', \n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206303, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>number_molecules</th>\n",
       "      <th>meth_k1</th>\n",
       "      <th>unmeth_k1</th>\n",
       "      <th>total_k1</th>\n",
       "      <th>meth_k3</th>\n",
       "      <th>unmeth_k3</th>\n",
       "      <th>total_k3</th>\n",
       "      <th>meth_k4</th>\n",
       "      <th>unmeth_k4</th>\n",
       "      <th>total_k4</th>\n",
       "      <th>frac_alpha_leq_25pct</th>\n",
       "      <th>frac_alpha_geq_75pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERS1022343</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERS1112536</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERS1112540</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERS1138462</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERS1138463</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id                                 region_id  number_molecules  meth_k1  unmeth_k1  total_k1  meth_k3  unmeth_k3  total_k3  meth_k4  unmeth_k4  total_k4  frac_alpha_leq_25pct  frac_alpha_geq_75pct\n",
       "0  ERS1022343  Immune_Broad_Neutro-chr1:9147789-9147871                21       64          6        70       23          1        27        5          0         7              0.047619              0.904762\n",
       "1  ERS1112536  Immune_Broad_Neutro-chr1:9147789-9147871                18       51         17        68       15          0        32        5          0        14              0.111111              0.666667\n",
       "2  ERS1112540  Immune_Broad_Neutro-chr1:9147789-9147871                13       32         16        48        9          3        20        4          1         9              0.153846              0.538462\n",
       "3  ERS1138462  Immune_Broad_Neutro-chr1:9147789-9147871                23       65         23        88       20          4        42        8          1        19              0.173913              0.695652\n",
       "4  ERS1138463  Immune_Broad_Neutro-chr1:9147789-9147871                15       42          9        51       14          1        21        2          0         6              0.066667              0.866667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
