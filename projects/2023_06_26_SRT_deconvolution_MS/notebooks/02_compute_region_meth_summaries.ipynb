{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Frag Meth Summaries for a Region Set\n",
    "\n",
    "Given a region set will compute frag scores for all samples in PAT Parquet files. Here we use hg38 PARQUET files.\n",
    "\n",
    "SET UP SDDs TO BE USED WITH SPARK PRIOR TO RUNNING THIS NOTEBOOK!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGIONS = 'dmr_literature'\n",
    "#REGIONS = 'loyfer2022_atlas_final_regions_top25'\n",
    "#REGIONS = 'dmr_tissue'\n",
    "#REGIONS = 'dmr_lunar_v6'\n",
    "REGIONS = 'deconvolution_v2.v23_conv.with_cpg_index'\n",
    "REGION_BED_COLS = [\n",
    "    'region_chr', 'region_start', 'region_end', \n",
    "    'region_cpg_index_min', 'region_cpg_index_max', 'region_id'\n",
    "]\n",
    "FILTER_CG_COUNT = 3\n",
    "FILTER_CG_COUNT_REGION = 1\n",
    "#--- Local paths\n",
    "ROOT_DIR = '/analysis/gh-aselewa/projects'\n",
    "PROJECT_SLUG = '2023_06_15_BCdeconvolution_AS'\n",
    "PROJECT_DIR = ROOT_DIR + '/{}'.format(PROJECT_SLUG)\n",
    "# Regions\n",
    "REGION_PATH = (\n",
    "    PROJECT_DIR + '/stage/panel_data/{regions}.bed'\n",
    ").format(regions=REGIONS)\n",
    "\n",
    "# CpG map; genomic coordinate to CpG index;\n",
    "CPG_MAP_PATH = PROJECT_DIR + '/stage/cpg_loci/cpg_loci_hg19.combined_annot.tsv.gz'\n",
    "\n",
    "# # PAT PARQUET files\n",
    "# PARQUET_PATH_LIST_HG19 = [\n",
    "#     '/temp/Loyfer_parquet',\n",
    "# ]\n",
    "\n",
    "# BLUEPRINT HG38: s3://gh-bi-lunar/public_data/blueprint/hg38_20160816.pat.db_version.parquet/\n",
    "PARQUET_PATH_LIST_HG38 = [\n",
    "    '/temp/blueprint_hg38/'\n",
    "]\n",
    "\n",
    "#--- Where to store results\n",
    "RESULTS_PATH = (\n",
    "    PROJECT_DIR + '/output/blueprint_meth_summaries/meth_summaries_cg_count_geq_{k}_{regions}.tsv.gz'\n",
    ").format(regions=REGIONS, k=FILTER_CG_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/17 00:14:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/17 00:14:57 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/06/17 00:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/06/17 00:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "## this works for PySpark v3.3.1 - only need to run this once\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages {aws_java},{aws_hadoop} pyspark-shell\".\\\n",
    "   format(aws_java=\"com.amazonaws:aws-java-sdk-bundle:1.11.271\",\n",
    "          aws_hadoop=\"org.apache.hadoop:hadoop-aws:3.1.2\")\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_15_BCdeconvolution_AS/lib/python3.7/site-packages/pyspark\"\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CpG Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_map = pd.read_csv(CPG_MAP_PATH, usecols=['chr', 'start', 'end', 'cpg_index', 'cpg_index_hg38'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 4.87 s, total: 19.9 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "ridxs = ~cpg_map['cpg_index_hg38'].isna()\n",
    "hg19_hg38_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index'], cpg_map[ridxs]['cpg_index_hg38'].astype(int)))\n",
    "hg38_hg19_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index_hg38'].astype(int), cpg_map[ridxs]['cpg_index']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df = pd.read_csv(REGION_PATH, sep='\\t', usecols=range(0, 6), names=REGION_BED_COLS)\n",
    "\n",
    "region_df['region_cpg_index_max'] -= 1\n",
    "region_df.sort_values('region_cpg_index_min', inplace=True)\n",
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min'].map(hg19_hg38_map)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max'].map(hg19_hg38_map)\n",
    "\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridxs = ~region_df['region_cpg_index_min_hg38'].isna()\n",
    "ridxs &= ~region_df['region_cpg_index_max_hg38'].isna()\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 1657)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg_count_hg19 = region_df['region_cpg_index_max']-region_df['region_cpg_index_min'] + 1\n",
    "cg_count_hg38 = region_df['region_cpg_index_max_hg38']-region_df['region_cpg_index_min_hg38'] + 1\n",
    "ridxs = (cg_count_hg19==cg_count_hg38)\n",
    "ridxs &= (cg_count_hg19>=FILTER_CG_COUNT_REGION)\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_chr                   object\n",
       "region_start                  int64\n",
       "region_end                    int64\n",
       "region_cpg_index_min          int64\n",
       "region_cpg_index_max          int64\n",
       "region_id                    object\n",
       "region_cpg_index_min_hg38     int64\n",
       "region_cpg_index_max_hg38     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min_hg38'].astype(int)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max_hg38'].astype(int)\n",
    "region_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAT PARQUET Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_COLS = [\n",
    "    'sample_id', 'molecule_id', 'chr', 'number_molecules',\n",
    "    'cpg_index_min', 'cpg_index_max', 'pat_string'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_parquet_files = [spark.read.parquet(ifile).select(*PAT_COLS) for ifile in PARQUET_PATH_LIST_HG19]\n",
    "# pat_hg19_ddf = functools.reduce(DataFrame.unionByName, pat_parquet_files)\n",
    "# pat_hg19_ddf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sample_id: string (nullable = true)\n",
      " |-- molecule_id: string (nullable = true)\n",
      " |-- chr: string (nullable = true)\n",
      " |-- number_molecules: integer (nullable = true)\n",
      " |-- cpg_index_min: long (nullable = true)\n",
      " |-- cpg_index_max: long (nullable = true)\n",
      " |-- pat_string: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat_parquet_files = [spark.read.parquet(ifile).select(*PAT_COLS) for ifile in PARQUET_PATH_LIST_HG38]\n",
    "pat_hg38_ddf = functools.reduce(DataFrame.unionByName, pat_parquet_files)\n",
    "pat_hg38_ddf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # simple mixture\n",
    "# pat_spikein = pat_hg38_ddf.filter(col('sample_id')==\"ERS661063\").sample(False, 0.1, seed=0)\n",
    "# pat_sample = pat_hg38_ddf.filter(col('sample_id')==\"ERS337607\")\n",
    "\n",
    "# pat_mix = pat_sample.union(pat_spikein)\n",
    "#pat_hg38_ddf.select('sample_id').distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragment Level Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTILES = [0.1, 0.25, 0.75, 0.9]\n",
    "KMERS = [1, 3, 4]\n",
    "RATES_LEQ = [0.25]\n",
    "RATES_GEQ = [0.75]\n",
    "\n",
    "RETURN_SCHEMA = StructType()\\\n",
    "    .add('sample_id', 'string')\\\n",
    "    .add('region_id', 'string')\\\n",
    "    .add('number_molecules', 'integer')\\\n",
    "    .add('meth_k1', 'integer')\\\n",
    "    .add('unmeth_k1', 'integer')\\\n",
    "    .add('total_k1', 'integer')\\\n",
    "    .add('meth_k3', 'integer')\\\n",
    "    .add('unmeth_k3', 'integer')\\\n",
    "    .add('total_k3', 'integer')\\\n",
    "    .add('meth_k4', 'integer')\\\n",
    "    .add('unmeth_k4', 'integer')\\\n",
    "    .add('total_k4', 'integer')\\\n",
    "    .add('frac_alpha_leq_25pct', 'float')\\\n",
    "    .add('frac_alpha_geq_75pct', 'float')\n",
    "\n",
    "def compute_frag_scores(cpg_number_cutoff: int) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns a function, used for reduce\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_frag_scores_inner(pat_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        data = pat_df.copy()\n",
    "        data['offset_min'] = (data['region_cpg_index_min'] - data['cpg_index_min']).clip(lower=0)\n",
    "        data['offset_max'] = np.minimum(\n",
    "            data['region_cpg_index_max'] - data['cpg_index_min'], \n",
    "            data['cpg_index_max'] - data['cpg_index_min'])\n",
    "        data['trimmed_pat'] = data.apply(lambda x: x['pat_string'][x['offset_min']:(x['offset_max']+1)], axis=1)\n",
    "        #--- Filter molecules based on observed CpG loci\n",
    "        observed_cpg_number = (data['trimmed_pat'].str.count('C')+data['trimmed_pat'].str.count('T'))\n",
    "        ridxs = (observed_cpg_number>=cpg_number_cutoff)\n",
    "        data = data[ridxs].copy()\n",
    "        if (data.shape[0]>0):\n",
    "            # Compute k-mer methylation states\n",
    "            for k in KMERS:\n",
    "                data['meth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[C]{%i}'%k, x, overlapped=True)))\n",
    "                data['unmeth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[T]{%i}'%k, x, overlapped=True)))\n",
    "                data['total_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[TC]{%i}'%k, x, overlapped=True)))\n",
    "            # Compute alpha distribution metrics\n",
    "            data['alpha'] = data['meth_k1']/data['total_k1']\n",
    "            for rate in RATES_LEQ:\n",
    "                data['frac_alpha_leq_%ipct'%(100*rate)] = np.where(data['alpha']<=rate, 1, 0)\n",
    "            for rate in RATES_GEQ:\n",
    "                data['frac_alpha_geq_%ipct'%(100*rate)] = np.where(data['alpha']>=rate, 1, 0)\n",
    "            # Expand entries that correspond to multiple molecules\n",
    "            data['number_molecules'] = data['number_molecules'].apply(lambda x: list(range(x)))\n",
    "            data = data.explode('number_molecules')\n",
    "            data['number_molecules'] = 1\n",
    "            # Aggregate metrics\n",
    "            rv = data.groupby(['region_id', 'sample_id'])\\\n",
    "                [['meth_k1', 'unmeth_k1', 'total_k1',\n",
    "                  'meth_k3', 'unmeth_k3', 'total_k3',\n",
    "                  'meth_k4', 'unmeth_k4', 'total_k4',\n",
    "                  'frac_alpha_leq_25pct', 'frac_alpha_geq_75pct', 'number_molecules']].sum()\\\n",
    "                .reset_index()\n",
    "            rv['frac_alpha_leq_25pct'] = rv['frac_alpha_leq_25pct']/rv['number_molecules']\n",
    "            rv['frac_alpha_geq_75pct'] = rv['frac_alpha_geq_75pct']/rv['number_molecules']\n",
    "        else:\n",
    "            rv = pd.DataFrame(columns=RETURN_SCHEMA.names)\n",
    "                      \n",
    "        \n",
    "        return rv[RETURN_SCHEMA.names]\n",
    "\n",
    "    return compute_frag_scores_inner\n",
    "\n",
    "\n",
    "compute_frag_scores_udf = compute_frag_scores(cpg_number_cutoff=FILTER_CG_COUNT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for HG19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# BATCH_SIZE = 20\n",
    "# region_df['batch'] = (np.arange(region_df.shape[0])/BATCH_SIZE).astype(int)\n",
    "# rv_scores = list()\n",
    "\n",
    "# for batch, batch_region_df in region_df.groupby('batch'):\n",
    "    \n",
    "#     rv_ov = list()\n",
    "#     print('---> Processing batch %i...' % batch)\n",
    "    \n",
    "#     for _, row in batch_region_df.iterrows():\n",
    "        \n",
    "#         # get PAT strings within each immune region\n",
    "#         ov_ddf = pat_hg19_ddf.filter(col('cpg_index_min')<=row['region_cpg_index_max'])\\\n",
    "#             .filter(col('cpg_index_max')>=row['region_cpg_index_min'])\\\n",
    "#             .withColumn('region_id', lit(row['region_id']))\\\n",
    "#             .withColumn('region_cpg_index_min', lit(row['region_cpg_index_min']))\\\n",
    "#             .withColumn('region_cpg_index_max', lit(row['region_cpg_index_max']))\n",
    "#         rv_ov.append(ov_ddf)\n",
    "    \n",
    "#     # for each region\n",
    "#     scores_df = functools.reduce(DataFrame.union, rv_ov)\\\n",
    "#         .groupby('region_id')\\\n",
    "#         .applyInPandas(compute_frag_scores_udf, schema=RETURN_SCHEMA)\\\n",
    "#         .toPandas()\n",
    "#     rv_scores.append(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_hg19_df = pd.concat(rv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for HG38 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 21...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 23...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 24...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 26...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 27...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 29...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 33...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 34...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 35...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 36...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 37...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 38...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 39...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 41...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 42...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 43...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 44...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 45...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 46...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 47...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 48...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 49...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 51...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 52...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 53...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 54...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 55...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 56...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 57...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 58...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 59...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 61...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 62...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 63...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 64...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 65...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 66...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 67...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 68...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 69...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 70...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 71...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 72...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 73...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 74...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 75...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 76...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 77...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 78...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 79...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 80...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 81...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing batch 82...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 249:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 2.39 s, total: 17.7 s\n",
      "Wall time: 1h 3min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 20\n",
    "region_df['batch'] = (np.arange(region_df.shape[0])/BATCH_SIZE).astype(int)\n",
    "rv_scores = list()\n",
    "for batch, batch_region_df in region_df.groupby('batch'):\n",
    "    rv_ov = list()\n",
    "    print('---> Processing batch %i...' % batch)\n",
    "    for _, row in batch_region_df.iterrows():\n",
    "        ov_ddf = pat_hg38_ddf.filter(col('cpg_index_min')<=row['region_cpg_index_max_hg38'])\\\n",
    "            .filter(col('cpg_index_max')>=row['region_cpg_index_min_hg38'])\\\n",
    "            .withColumn('region_id', lit(row['region_id']))\\\n",
    "            .withColumn('region_cpg_index_min', lit(row['region_cpg_index_min_hg38']))\\\n",
    "            .withColumn('region_cpg_index_max', lit(row['region_cpg_index_max_hg38']))\n",
    "        rv_ov.append(ov_ddf)\n",
    "    scores_df = functools.reduce(DataFrame.union, rv_ov)\\\n",
    "        .groupby('region_id')\\\n",
    "        .applyInPandas(compute_frag_scores_udf, schema=RETURN_SCHEMA)\\\n",
    "        .toPandas()\n",
    "    rv_scores.append(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_hg38_df = pd.concat(rv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206303, 1648, 127)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores_df = pd.concat([scores_hg19_df, scores_hg38_df])\n",
    "scores_df = scores_hg38_df\n",
    "scores_df.shape[0], scores_df['region_id'].nunique(), scores_df['sample_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.13 s, sys: 118 Âµs, total: 3.13 s\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores_df.to_csv(('output/analysis/gh-aselewa/projects/2023_06_15_BCdeconvolution_AS/meth_summaries_cg_count_geq_{k}_{regions}.tsv.gz').format(regions=REGIONS, k=FILTER_CG_COUNT),\n",
    "                 sep='\\t', \n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
