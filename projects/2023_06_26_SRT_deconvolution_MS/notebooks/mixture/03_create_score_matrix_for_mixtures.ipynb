{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# UPDATE HOME!\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark\"\n",
    "# THIS needs to be set-up before running the notebook\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.ui.showConsoleProgress\", \"True\")\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = 'deconvolution_v2.v23_conv.with_cpg_index'\n",
    "REGION_BED_COLS = [\n",
    "    'region_chr', 'region_start', 'region_end', \n",
    "    'region_cpg_index_min', 'region_cpg_index_max', 'region_id'\n",
    "]\n",
    "FILTER_CG_COUNT = 3\n",
    "FILTER_CG_COUNT_REGION = 1\n",
    "\n",
    "#--- Local paths\n",
    "ROOT_DIR = '/analysis/gh-msun/projects'\n",
    "PROJECT_SLUG = '2023_06_26_SRT_deconvolution_MS'\n",
    "PROJECT_DIR = ROOT_DIR + '/{}'.format(PROJECT_SLUG)\n",
    "\n",
    "# Regions\n",
    "REGION_PATH = (\n",
    "    PROJECT_DIR + '/stage/panel_data/{regions}.bed'\n",
    ").format(regions=REGIONS)\n",
    "\n",
    "# CpG map; genomic coordinate to CpG index;\n",
    "CPG_MAP_PATH = PROJECT_DIR + '/stage/cpg_loci/cpg_loci_hg19.combined_annot.tsv.gz'\n",
    "\n",
    "#--- Where to store results\n",
    "RESULT_PATH = PROJECT_DIR + '/output/methyl_score/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CpG Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_map = pd.read_csv(CPG_MAP_PATH, usecols=['chr', 'start', 'end', 'cpg_index', 'cpg_index_hg38'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 5.06 s, total: 20.4 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridxs = ~cpg_map['cpg_index_hg38'].isna()\n",
    "hg19_hg38_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index'], cpg_map[ridxs]['cpg_index_hg38'].astype(int)))\n",
    "hg38_hg19_map = dict(itertools.zip_longest(cpg_map[ridxs]['cpg_index_hg38'].astype(int), cpg_map[ridxs]['cpg_index']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df = pd.read_csv(REGION_PATH, sep='\\t', usecols=range(0, 6), names=REGION_BED_COLS)\n",
    "\n",
    "region_df['region_cpg_index_max'] -= 1\n",
    "region_df.sort_values('region_cpg_index_min', inplace=True)\n",
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min'].map(hg19_hg38_map)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max'].map(hg19_hg38_map)\n",
    "\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 1658)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridxs = ~region_df['region_cpg_index_min_hg38'].isna()\n",
    "ridxs &= ~region_df['region_cpg_index_max_hg38'].isna()\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 1657)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg_count_hg19 = region_df['region_cpg_index_max']-region_df['region_cpg_index_min'] + 1\n",
    "cg_count_hg38 = region_df['region_cpg_index_max_hg38']-region_df['region_cpg_index_min_hg38'] + 1\n",
    "ridxs = (cg_count_hg19==cg_count_hg38)\n",
    "ridxs &= (cg_count_hg19>=FILTER_CG_COUNT_REGION)\n",
    "region_df = region_df[ridxs].copy()\n",
    "region_df.shape[0], region_df['region_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df['region_cpg_index_min_hg38'] = region_df['region_cpg_index_min_hg38'].astype(int)\n",
    "region_df['region_cpg_index_max_hg38'] = region_df['region_cpg_index_max_hg38'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_chr</th>\n",
       "      <th>region_start</th>\n",
       "      <th>region_end</th>\n",
       "      <th>region_cpg_index_min</th>\n",
       "      <th>region_cpg_index_max</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_cpg_index_min_hg38</th>\n",
       "      <th>region_cpg_index_max_hg38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1114771</td>\n",
       "      <td>1114971</td>\n",
       "      <td>20117</td>\n",
       "      <td>20129</td>\n",
       "      <td>Immune_Broad_B-chr1:1114772-1114971</td>\n",
       "      <td>21119</td>\n",
       "      <td>21131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157450</td>\n",
       "      <td>1157720</td>\n",
       "      <td>21684</td>\n",
       "      <td>21703</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157451-1157720</td>\n",
       "      <td>22686</td>\n",
       "      <td>22705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157879</td>\n",
       "      <td>1158277</td>\n",
       "      <td>21710</td>\n",
       "      <td>21726</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157880-1158277</td>\n",
       "      <td>22712</td>\n",
       "      <td>22728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chr1</td>\n",
       "      <td>6341182</td>\n",
       "      <td>6341377</td>\n",
       "      <td>140667</td>\n",
       "      <td>140681</td>\n",
       "      <td>Immune_Broad_Eosi-chr1:6341183-6341377</td>\n",
       "      <td>142368</td>\n",
       "      <td>142382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chr1</td>\n",
       "      <td>9147788</td>\n",
       "      <td>9147871</td>\n",
       "      <td>188605</td>\n",
       "      <td>188608</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "      <td>190307</td>\n",
       "      <td>190310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_chr  region_start  region_end  region_cpg_index_min  region_cpg_index_max                                 region_id  region_cpg_index_min_hg38  region_cpg_index_max_hg38\n",
       "0        chr1       1114771     1114971                 20117                 20129       Immune_Broad_B-chr1:1114772-1114971                      21119                      21131\n",
       "1        chr1       1157450     1157720                 21684                 21703      Immune_Broad_NK-chr1:1157451-1157720                      22686                      22705\n",
       "2        chr1       1157879     1158277                 21710                 21726      Immune_Broad_NK-chr1:1157880-1158277                      22712                      22728\n",
       "14       chr1       6341182     6341377                140667                140681    Immune_Broad_Eosi-chr1:6341183-6341377                     142368                     142382\n",
       "19       chr1       9147788     9147871                188605                188608  Immune_Broad_Neutro-chr1:9147789-9147871                     190307                     190310"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Restrict to immune regions\n",
    "#-------------- CHANGE HERE FOR DIFFERENT REGION SUBSET ----------------------\n",
    "# BLUEPRINT immune regions\n",
    "ATLAS_PATH = PROJECT_DIR + f'/output/deconv_inhouse_v2.atlas.tsv.gz'\n",
    "atlas = pd.read_csv(ATLAS_PATH, sep='\\t')\n",
    "subset_region_set = set(atlas.region_id)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# filter regions down to regions of interest\n",
    "region_df = region_df[region_df['region_id'].isin(subset_region_set)]\n",
    "region_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragment Level Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(directory):\n",
    "\n",
    "    list_paths = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        list_paths.append(os.path.abspath(os.path.join(directory, filename)))\n",
    "\n",
    "    return(list_paths)\n",
    "\n",
    "\n",
    "def compute_frag_scores(cpg_number_cutoff: int) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns a function, used for reduce\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_frag_scores_inner(pat_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        data = pat_df.copy()\n",
    "        data['offset_min'] = (data['region_cpg_index_min'] - data['cpg_index_min']).clip(lower=0)\n",
    "        data['offset_max'] = np.minimum(\n",
    "            data['region_cpg_index_max'] - data['cpg_index_min'], \n",
    "            data['cpg_index_max'] - data['cpg_index_min'])\n",
    "        data['trimmed_pat'] = data.apply(lambda x: x['pat_string'][x['offset_min']:(x['offset_max']+1)], axis=1)\n",
    "        #--- Filter molecules based on observed CpG loci\n",
    "        observed_cpg_number = (data['trimmed_pat'].str.count('C')+data['trimmed_pat'].str.count('T'))\n",
    "        ridxs = (observed_cpg_number>=cpg_number_cutoff)\n",
    "        data = data[ridxs].copy()\n",
    "        if (data.shape[0]>0):\n",
    "            # Compute k-mer methylation states\n",
    "            for k in KMERS:\n",
    "                data['meth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[C]{%i}'%k, x, overlapped=True)))\n",
    "                data['unmeth_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[T]{%i}'%k, x, overlapped=True)))\n",
    "                data['total_k%i'%k] = data['trimmed_pat']\\\n",
    "                    .apply(lambda x: len(re.findall('[TC]{%i}'%k, x, overlapped=True)))\n",
    "            # Compute alpha distribution metrics\n",
    "            data['alpha'] = data['meth_k1']/data['total_k1']\n",
    "            for rate in RATES_LEQ:\n",
    "                data['frac_alpha_leq_%ipct'%(100*rate)] = np.where(data['alpha']<=rate, 1, 0)\n",
    "            for rate in RATES_GEQ:\n",
    "                data['frac_alpha_geq_%ipct'%(100*rate)] = np.where(data['alpha']>=rate, 1, 0)\n",
    "            # Expand entries that correspond to multiple molecules\n",
    "            data['number_molecules'] = data['number_molecules'].apply(lambda x: list(range(x)))\n",
    "            data = data.explode('number_molecules')\n",
    "            data['number_molecules'] = 1\n",
    "            # Aggregate metrics\n",
    "            #rv = data.groupby(['region_id', 'sample_id'])\\\n",
    "            rv = data.groupby(['region_id'])\\\n",
    "                [['meth_k1', 'unmeth_k1', 'total_k1',\n",
    "                  'meth_k3', 'unmeth_k3', 'total_k3',\n",
    "                  'meth_k4', 'unmeth_k4', 'total_k4',\n",
    "                  'frac_alpha_leq_25pct', 'frac_alpha_geq_75pct', 'number_molecules']].sum()\\\n",
    "                .reset_index()\n",
    "            rv['frac_alpha_leq_25pct'] = rv['frac_alpha_leq_25pct']/rv['number_molecules']\n",
    "            rv['frac_alpha_geq_75pct'] = rv['frac_alpha_geq_75pct']/rv['number_molecules']\n",
    "        else:\n",
    "            rv = pd.DataFrame(columns=RETURN_SCHEMA.names)\n",
    "                      \n",
    "        \n",
    "        return rv[RETURN_SCHEMA.names]\n",
    "\n",
    "    return compute_frag_scores_inner\n",
    "\n",
    "\n",
    "def score_matrix(parquet_path, pat_cols, region_df, batch_size, schema, save=False, verbose=False):\n",
    "    '''\n",
    "    one parquet file --> one score matrix\n",
    "    '''\n",
    "    # Load single parquet file\n",
    "    pat_df = spark.read.parquet(parquet_path).select(*pat_cols)\n",
    "    \n",
    "    # Compute scores by batch\n",
    "    region_df['batch'] = (np.arange(region_df.shape[0])/batch_size).astype(int)\n",
    "    rv_scores = list()\n",
    "    \n",
    "    for batch, batch_region_df in region_df.groupby('batch'):\n",
    "        rv_ov = list()\n",
    "        if verbose: print('----------> Processing batch %i...' % batch)\n",
    "        for _, row in batch_region_df.iterrows():\n",
    "            ov_ddf = pat_df.filter(col('cpg_index_min')<=row['region_cpg_index_max_hg38'])\\\n",
    "                .filter(col('cpg_index_max') >= row['region_cpg_index_min_hg38'])\\\n",
    "                .withColumn('region_id', lit(row['region_id']))\\\n",
    "                .withColumn('region_cpg_index_min', lit(row['region_cpg_index_min_hg38']))\\\n",
    "                .withColumn('region_cpg_index_max', lit(row['region_cpg_index_max_hg38']))\n",
    "            rv_ov.append(ov_ddf)\n",
    "        scores_df = functools.reduce(DataFrame.union, rv_ov)\\\n",
    "            .groupby('region_id')\\\n",
    "            .applyInPandas(compute_frag_scores_udf, schema=RETURN_SCHEMA)\\\n",
    "            .toPandas()\n",
    "        rv_scores.append(scores_df)\n",
    "    \n",
    "    scores_df = pd.concat(rv_scores)\n",
    "        \n",
    "    return scores_df\n",
    "\n",
    "\n",
    "def score_matrix_from_mixture_directory(dir_path, result_path, pat_cols, region_df, batch_size, schema, save=False, verbose=False):\n",
    "    '''\n",
    "    mixture directory or replicate mixture parquets --> score matrix per replicate mixture parquet\n",
    "    '''\n",
    "    \n",
    "    # create result directory\n",
    "#     dir_name = os.path.basename(os.path.normpath(dir_path))\n",
    "#     print(dir_name)\n",
    "    result_dir_path = result_path # + dir_name\n",
    "    \n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.mkdir(result_dir_path)\n",
    "        print(\"Folder %s created!\" % result_dir_path)\n",
    "    else:\n",
    "        print(\"Folder %s already exists\" % result_dir_path)\n",
    "    \n",
    "    # given directory path grab all parquet --> load path strings into a list\n",
    "    list_parquet_paths = get_file_paths(dir_path)\n",
    "    \n",
    "    # check for .parquet\n",
    "    \n",
    "    # for each parquet in the list run score_matrix\n",
    "    #list_score_df = []\n",
    "    \n",
    "    for path in list_parquet_paths:\n",
    "        if verbose: print(f'-----> Computing score matrix for {path}')\n",
    "        score_df = score_matrix(parquet_path=path, \n",
    "                                pat_cols=pat_cols, \n",
    "                                region_df=region_df, \n",
    "                                batch_size=batch_size, \n",
    "                                schema=schema, \n",
    "                                save=save, \n",
    "                                verbose=verbose)\n",
    "      #  list_score_df.append(score_df)\n",
    "    \n",
    "        # save each score df for each replicate mixture\n",
    "        if save:\n",
    "            file_name = os.path.basename(path)\n",
    "            file_name_without_ext = os.path.splitext(file_name)[0]\n",
    "            save_path = result_dir_path + '/' + file_name_without_ext + '.tsv.gz'\n",
    "            print(save_path)\n",
    "            score_df.to_csv(save_path,\n",
    "                 sep='\\t', \n",
    "                 index=False)\n",
    "    \n",
    "    print('>>> Mixture score matrices complete. <<<')\n",
    "\n",
    "\n",
    "def score_matrix_from_experiment_directory(dir_path_to_experiment, result_path, pat_cols, region_df, batch_size, schema, save=False, verbose=False):\n",
    "    '''\n",
    "    dir_path_to_experiment\n",
    "    '''\n",
    "    \n",
    "    # create result directory\n",
    "    dir_name = os.path.basename(os.path.normpath(dir_path_to_experiment))\n",
    "    result_dir_path = result_path + dir_name\n",
    "    \n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.mkdir(result_dir_path)\n",
    "        print(\"Folder %s created!\" % result_dir_path)\n",
    "    else:\n",
    "        print(\"Folder %s already exists\" % result_dir_path)\n",
    "        \n",
    "    # given directory path grab all mixture directories containing parquet\n",
    "    list_mixture_dir_paths = get_file_paths(dir_path_to_experiment)\n",
    "    \n",
    "    # iterate through each mixture directory\n",
    "    for path in list_mixture_dir_paths:\n",
    "    \n",
    "        if verbose: print(f'--> Computing score matrices for {path}')\n",
    "        \n",
    "        mixture_dir_name = os.path.basename(path)\n",
    "        file_name_without_ext = os.path.splitext(mixture_dir_name)[0]\n",
    "        save_path = result_dir_path + '/' + file_name_without_ext + '/'\n",
    "\n",
    "        score_matrix_from_mixture_directory(dir_path=path, \n",
    "                                            result_path=save_path,\n",
    "                                            pat_cols=pat_cols, \n",
    "                                            region_df=region_df, \n",
    "                                            batch_size=batch_size, \n",
    "                                            schema=schema, \n",
    "                                            save=save, \n",
    "                                            verbose=verbose)\n",
    "        \n",
    "    print('>>>>> Experiment score matrices complete. <<<<<')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=20\n",
    "\n",
    "PAT_COLS = [\n",
    "    'molecule_id', 'chr', 'number_molecules',\n",
    "    'cpg_index_min', 'cpg_index_max', 'pat_string'\n",
    "]\n",
    "\n",
    "QUANTILES = [0.1, 0.25, 0.75, 0.9]\n",
    "KMERS = [1, 3, 4]\n",
    "RATES_LEQ = [0.25]\n",
    "RATES_GEQ = [0.75]\n",
    "\n",
    "RETURN_SCHEMA = StructType()\\\n",
    "    .add('region_id', 'string')\\\n",
    "    .add('number_molecules', 'integer')\\\n",
    "    .add('meth_k1', 'integer')\\\n",
    "    .add('unmeth_k1', 'integer')\\\n",
    "    .add('total_k1', 'integer')\\\n",
    "    .add('meth_k3', 'integer')\\\n",
    "    .add('unmeth_k3', 'integer')\\\n",
    "    .add('total_k3', 'integer')\\\n",
    "    .add('meth_k4', 'integer')\\\n",
    "    .add('unmeth_k4', 'integer')\\\n",
    "    .add('total_k4', 'integer')\\\n",
    "    .add('frac_alpha_leq_25pct', 'float')\\\n",
    "    .add('frac_alpha_geq_75pct', 'float')\n",
    "#     .add('sample_id', 'string')\\\n",
    "\n",
    "\n",
    "compute_frag_scores_udf = compute_frag_scores(cpg_number_cutoff=FILTER_CG_COUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture already exists\n",
      "--> Computing score matrices for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888\n",
      "Folder /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/ already exists\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix0_seed_83723.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix0_seed_83723.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix1_seed_452891.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix1_seed_452891.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix2_seed_612330.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix2_seed_612330.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix3_seed_466724.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix3_seed_466724.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix4_seed_960318.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix4_seed_960318.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix5_seed_520710.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix5_seed_520710.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix6_seed_404706.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix6_seed_404706.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix7_seed_660471.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix7_seed_660471.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix8_seed_392926.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix8_seed_392926.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix9_seed_567724.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888//mix9_seed_567724.tsv.gz\n",
      ">>> Mixture score matrices complete. <<<\n",
      "--> Computing score matrices for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2\n",
      "Folder /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/ created!\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix0_seed_83723.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix0_seed_83723.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix1_seed_452891.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix1_seed_452891.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix2_seed_612330.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix2_seed_612330.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix3_seed_466724.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix3_seed_466724.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix4_seed_960318.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix4_seed_960318.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix5_seed_520710.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix5_seed_520710.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix6_seed_404706.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix6_seed_404706.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix7_seed_660471.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix7_seed_660471.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix8_seed_392926.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix8_seed_392926.tsv.gz\n",
      "-----> Computing score matrix for /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2/mix9_seed_567724.parquet\n",
      "----------> Processing batch 0...\n",
      "----------> Processing batch 1...\n",
      "----------> Processing batch 2...\n",
      "----------> Processing batch 3...\n",
      "----------> Processing batch 4...\n",
      "----------> Processing batch 5...\n",
      "----------> Processing batch 6...\n",
      "----------> Processing batch 7...\n",
      "----------> Processing batch 8...\n",
      "----------> Processing batch 9...\n",
      "----------> Processing batch 10...\n",
      "----------> Processing batch 11...\n",
      "----------> Processing batch 12...\n",
      "----------> Processing batch 13...\n",
      "/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888_2//mix9_seed_567724.tsv.gz\n",
      ">>> Mixture score matrices complete. <<<\n",
      ">>>>> Experiment score matrices complete. <<<<<\n",
      "CPU times: user 13.5 s, sys: 2.7 s, total: 16.2 s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_matrix_from_experiment_directory(dir_path_to_experiment = '/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/', \n",
    "                                       result_path = '/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/methyl_score/', \n",
    "                                       pat_cols = PAT_COLS, \n",
    "                                       region_df = region_df, \n",
    "                                       batch_size = 20, \n",
    "                                       schema = RETURN_SCHEMA, \n",
    "                                       save=True, \n",
    "                                       verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# DIR_PATH = '/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/'+'mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888'\n",
    "# scores_df_list = score_matrix_from_mixture_directory(dir_path=DIR_PATH, \n",
    "#                                                     result_path=RESULT_PATH,\n",
    "#                                                     pat_cols=PAT_COLS, \n",
    "#                                                     region_df=region_df, \n",
    "#                                                     batch_size=BATCH_SIZE, \n",
    "#                                                     schema=RETURN_SCHEMA, \n",
    "#                                                     save=False,\n",
    "#                                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
