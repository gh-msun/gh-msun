{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for creating mixtures from cell type parquet files created in notebook `01_combine_subjects_by_celltype.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# UPDATE HOME!\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark\"\n",
    "# THIS needs to be set-up before running the notebook\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.ui.showConsoleProgress\", \"True\")\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling in PySpark\n",
    "The `sample()` function takes fraction of reads to sample, not the number of reads to sample. \\\n",
    "We can compute the fraction from the total number of reads and the number of desired reads to sample. \\\n",
    "Mapping: `(N rows to sample) --> (F fraction to sample)`\n",
    "```\n",
    "N rows to sample = fraction * total reads\n",
    "fraction = N rows to sample / total reads\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_dataframe(parquet_path, cell_types, verbose=True):\n",
    "    '''\n",
    "    Load parquet file by cell type and count the number of rows.\n",
    "    Takes in parquet files where the samples have been collapsed by cell type.\n",
    "    \n",
    "    Arguments:\n",
    "    parquet_path -- path to the directory with source cell type reads to mix from\n",
    "    cell_types -- list of cell type to load for mixing\n",
    "    '''\n",
    "    \n",
    "    # Load the parquet files for selected cell types & count rows\n",
    "    parquet_df = []\n",
    "    total_reads_per_celltype = []\n",
    "    \n",
    "    if verbose: print('>>> Load parquet files and count rows... <<<')\n",
    "    for cell_type in cell_types:\n",
    "        if verbose: print(f'----------> Loading cell type: {cell_type}')\n",
    "        df = spark.read.parquet(f'{parquet_path}collapsed_reads_{cell_type}/')\n",
    "        parquet_df.append(df)\n",
    "        total_reads_per_celltype.append(df.count())\n",
    "\n",
    "    total_reads_per_celltype = np.array(total_reads_per_celltype)\n",
    "    \n",
    "    if verbose: print('>>> Complete. <<< \\n')\n",
    "\n",
    "    return(parquet_df, total_reads_per_celltype)\n",
    "    \n",
    "\n",
    "def one_to_many_seeds(seed, n):\n",
    "    '''\n",
    "    Generate seeds (between 0 and 1 million)\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    seeds = [random.randint(0, 10**6) for _ in range(n)]\n",
    "    return(seeds)\n",
    "\n",
    "\n",
    "def generate_mixture_dir_name_string(list_celltype_name, list_proportion):\n",
    "    '''\n",
    "    Generate name for cell type given list of cell type name and proportions\n",
    "    E = '0.'\n",
    "    e.g. ['B', 'CD4', 'CD8', 'NK', 'Mono', 'Neutro'] and np.array([0.05, 0.015, 0.5, 0.6, 0.7, 0]).\n",
    "    Output string: 'E05B_E015CD4_E5CD8_E6NK_E7MONO_ENEUTRO'\n",
    "    '''\n",
    "    \n",
    "    # Replace '0.' with 'E', add corresponding letter from list_a, and join all elements with '_'\n",
    "    dir_name = '_'.join(['E' + str(b)[2:] + a.upper() for a, b in zip(list_celltype_name, list_proportion)])\n",
    "    return(dir_name)\n",
    "\n",
    "\n",
    "def reverse_translate(input_string):\n",
    "    pass\n",
    "\n",
    "\n",
    "def mix_celltypes(parquet_df, total_reads_per_celltype, cell_types, total_reads_to_sample, proportions, seed, result_path, verbose, save=False, itr=None):\n",
    "    ''' Mix reads from different cell types based on given proportion and total reads to sample.\n",
    "    Note: Data is loaded once in mix_celltypes_n_times() to avoid loading dataframes repeatedly.\n",
    "    \n",
    "    Arguments:\n",
    "    paquet_df -- list of dataframes loaded in mix_celltypes_n_times()\n",
    "    total_reads_per_celltype -- calculated while reading in dataframe (nrow of each df)\n",
    "    cell_types -- list of cell type to mix\n",
    "    total_reads_to_sample -- integer representing the total number of reads to sample across all cell types\n",
    "    proportions -- list of proportions to sample for each cell type\n",
    "    seed -- seed for .sample()\n",
    "    result_path -- path to output parquet file (e.g. experiment/mixture/mix_50B_50CD4/)\n",
    "    itr -- mixture iteration for creating multiple mixtures (for file naming)\n",
    "    \n",
    "    Output:\n",
    "    mixture -- pyspark.sql.dataframe.DataFrame\n",
    "    '''\n",
    "    \n",
    "    if verbose: print(f'--> seed: {seed}')\n",
    "    \n",
    "    # compute fraction to sample for each cell type (later convert to index)\n",
    "    n_reads_to_sample = proportions * total_reads_to_sample\n",
    "    sampling_fraction = n_reads_to_sample / total_reads_per_celltype\n",
    "    if verbose: print(f'Sampling fraction: {sampling_fraction}')\n",
    "    \n",
    "    # sample reads from each cell type\n",
    "    sampled_df = []\n",
    "    \n",
    "    if verbose: print('--> Sample rows for each cell type...')\n",
    "    for i in range(0, len(cell_types)):\n",
    "        if verbose: print(f'----------> Sampling cell type: {cell_types[i]}')\n",
    "        df = parquet_df[i]\n",
    "        frac = sampling_fraction[i]\n",
    "        df_sample = df.sample(False, frac, seed)\n",
    "        sampled_df.append(df_sample)\n",
    "        n_sampled = df_sample.count()\n",
    "        if verbose: print(f'----------> {n_sampled}')\n",
    "    \n",
    "    # combine reads\n",
    "    if verbose: print('--> Combining sampled reads into one dataframe...')\n",
    "    mixture = functools.reduce(DataFrame.union, sampled_df)\n",
    "    \n",
    "    if save:\n",
    "        # create file name \n",
    "        seed_string = str(int(seed))\n",
    "        celltype_string = '_'.join(cell_types)\n",
    "        proportion_str = [str(i) for i in proportions]\n",
    "        proportion_string = '_'.join(proportion_str)\n",
    "        mixture_itr = f'mix{itr}_'\n",
    "        file_name = mixture_itr + \\\n",
    "                    f'seed{seed_string}' + \\\n",
    "                    '.parquet/'\n",
    "\n",
    "        if verbose: print('--> Saving parquet file...')\n",
    "        save_path = result_path + file_name\n",
    "        mixture.write.mode('overwrite').parquet(save_path)\n",
    "        if verbose: print(f'--> Saved to: {save_path}')\n",
    "    \n",
    "    return(mixture)\n",
    "\n",
    "\n",
    "def mix_celltypes_n_times(parquet_df, total_reads_per_celltype, n, cell_types, cell_type_abridged_name, total_reads_to_sample, proportions, seed, result_path, verbose, save=False):\n",
    "    '''Create n mixtures by mixing reads from different cell types based on given proportion and total reads to sample. \n",
    "    Loads the parquet files.\n",
    "    Calls mix_celltypes() n times.\n",
    "    \n",
    "    Arguments:\n",
    "    n -- total number of mixtures to make\n",
    "    cell_types -- list of cell type to mix\n",
    "    cell_type_abridged_name -- abridged name of cell types to be used for naming output directory\n",
    "    total_reads_to_sample -- integer representing the total number of reads to sample across all cell types\n",
    "    proportions -- list of proportions to sample for each cell type\n",
    "    seed -- seed for .sample()\n",
    "    result_path -- path to the mixture directory where all the mixtures for each proportion list will be saved (e.g. experiment/mixture/)\n",
    "    '''\n",
    "    \n",
    "    # Create output directory\n",
    "    dir_name = generate_mixture_dir_name_string(cell_type_abridged_name, proportions)\n",
    "    dir_name = dir_name + '/' #+ '_seed' + str(seed) + '/'\n",
    "    dir_path = result_path + dir_name\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "    # generate seeds\n",
    "    seeds = one_to_many_seeds(seed, n=n)\n",
    "    \n",
    "    # Create n mixtures   \n",
    "    for i in range(0, n):\n",
    "        \n",
    "        print(f'----------> Creating mixture {i}... ')\n",
    "        mixture = mix_celltypes(parquet_df=parquet_df,\n",
    "                               total_reads_per_celltype=total_reads_per_celltype,\n",
    "                               cell_types=cell_types,\n",
    "                               total_reads_to_sample=total_reads_to_sample, \n",
    "                               proportions=proportions, \n",
    "                               seed=seeds[i],\n",
    "                               result_path=dir_path,\n",
    "                               save=save,\n",
    "                               itr=i,\n",
    "                               verbose=verbose)\n",
    "\n",
    "\n",
    "def mix_celltypes_multiple_proportions(parquet_df, total_reads_per_celltype, n, cell_types, cell_type_abridged_name, total_reads_to_sample, list_of_proportions, seed, result_path, verbose=False, save=False):\n",
    "    '''Create n mixtures by mixing reads from different cell types based on given proportion and total reads to sample. \n",
    "    Calls mix_celltypes_n_times()  times.\n",
    "    \n",
    "    Arguments:\n",
    "    n -- total number of replicate mixtures to make per proportion\n",
    "    cell_types -- list of cell type to mix\n",
    "    cell_type_abridged_name -- abridged name of cell types to be used for naming output directory\n",
    "    total_reads_to_sample -- integer representing the total number of reads to sample across all cell types\n",
    "    list_of_proportions -- list(list()) list of list of proportions to sample for each cell type\n",
    "    seed -- seed for .sample()\n",
    "    result_path -- path to the mixture directory where all the mixtures for each proportion list will be saved (e.g. experiment/mixture/)\n",
    "    '''\n",
    "    \n",
    "    print('>>> Start mixing... <<<')\n",
    "    \n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    \n",
    "    seeds = one_to_many_seeds(seed, n=n)\n",
    "    i = 0\n",
    "\n",
    "    for proportion in list_of_proportions:\n",
    "\n",
    "        print(f\"--> PROPORTION: {proportion}\")\n",
    "        mix_celltypes_n_times(\n",
    "                     parquet_df=parquet_df,\n",
    "                     total_reads_per_celltype=total_reads_per_celltype,\n",
    "                     n=n,\n",
    "                     cell_types=cell_types,\n",
    "                     cell_type_abridged_name=cell_type_abridged_name,\n",
    "                     total_reads_to_sample=total_reads_to_sample, \n",
    "                     proportions=proportion, \n",
    "                     seed=seeds[i],\n",
    "                     result_path=result_path,\n",
    "                     save=save,\n",
    "                     verbose=verbose)\n",
    "        i += 1\n",
    "    \n",
    "    print(\">>> Complete. <<< \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Load parquet files and count rows... <<<\n",
      "----------> Loading cell type: Blueprint-B\n",
      "----------> Loading cell type: Blueprint-CD4\n",
      "----------> Loading cell type: Blueprint-CD8\n",
      "----------> Loading cell type: Blueprint-NK\n",
      "----------> Loading cell type: Blueprint-Mono\n",
      "----------> Loading cell type: Blueprint-Neutro\n",
      ">>> Complete. <<< \n",
      "\n",
      ">>> Start mixing... <<<\n",
      "--> PROPORTION: [0.1  0.18 0.18 0.18 0.18 0.18]\n",
      "----------> Creating mixture 0... \n",
      "----------> Creating mixture 1... \n",
      "----------> Creating mixture 2... \n",
      "----------> Creating mixture 3... \n",
      "----------> Creating mixture 4... \n",
      "----------> Creating mixture 5... \n",
      "----------> Creating mixture 6... \n",
      "----------> Creating mixture 7... \n",
      "----------> Creating mixture 8... \n",
      "----------> Creating mixture 9... \n",
      "--> PROPORTION: [0.01  0.198 0.198 0.198 0.198 0.198]\n",
      "----------> Creating mixture 0... \n",
      "----------> Creating mixture 1... \n",
      "----------> Creating mixture 2... \n",
      "----------> Creating mixture 3... \n",
      "----------> Creating mixture 4... \n",
      "----------> Creating mixture 5... \n",
      "----------> Creating mixture 6... \n",
      "----------> Creating mixture 7... \n",
      "----------> Creating mixture 8... \n",
      "----------> Creating mixture 9... \n",
      "--> PROPORTION: [0.001  0.1998 0.1998 0.1998 0.1998 0.1998]\n",
      "----------> Creating mixture 0... \n",
      "----------> Creating mixture 1... \n",
      "----------> Creating mixture 2... \n",
      "----------> Creating mixture 3... \n",
      "----------> Creating mixture 4... \n",
      "----------> Creating mixture 5... \n",
      "----------> Creating mixture 6... \n",
      "----------> Creating mixture 7... \n",
      "----------> Creating mixture 8... \n",
      "----------> Creating mixture 9... \n",
      ">>> Complete. <<< \n",
      "\n",
      "CPU times: user 153 ms, sys: 31.4 ms, total: 185 ms\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#--- Local paths\n",
    "ROOT_DIR = '/analysis/gh-msun/projects'\n",
    "PROJECT_SLUG = '2023_06_26_SRT_deconvolution_MS'\n",
    "PROJECT_DIR = ROOT_DIR + '/{}'.format(PROJECT_SLUG)\n",
    "EXPERIMENT_NAME = 'BLUEPRINT_B'\n",
    "PARQUET_PATH = PROJECT_DIR + '/output/mixture_source/'\n",
    "RESULT_PATH = PROJECT_DIR + f'/output/experiment/{EXPERIMENT_NAME}/mixture/'\n",
    "\n",
    "def punif(p, n):\n",
    "    return((1-p)/n)\n",
    "\n",
    "k=5\n",
    "p1, p2, p3 = 0.1, 0.01, 0.001\n",
    "p1_, p2_, p3_ = punif(p1, k), punif(p2, k), punif(p3, k)\n",
    "\n",
    "PROPORTIONS = [np.array([p1, p1_, p1_, p1_, p1_, p1_]),\n",
    "               np.array([p2, p2_, p2_, p2_, p2_, p2_]),\n",
    "               np.array([p3, p3_, p3_, p3_, p3_, p3_])]\n",
    "\n",
    "N=10\n",
    "SEED = 888\n",
    "TOTAL_READS_TO_SAMPLE = 1000000\n",
    "CELLTYPES = ['Blueprint-B', 'Blueprint-CD4', 'Blueprint-CD8', 'Blueprint-NK', 'Blueprint-Mono', 'Blueprint-Neutro']\n",
    "CELLTYPES_ABRIDGED_NAME = ['B', 'CD4', 'CD8', 'NK', 'Mono', 'Neutro']\n",
    "\n",
    "\n",
    "# load parquet files for each celltype & count rows\n",
    "parquet_df, total_reads_per_celltype = load_parquet_dataframe(parquet_path=PARQUET_PATH,\n",
    "                                                              cell_types=CELLTYPES,\n",
    "                                                              verbose=True)\n",
    "\n",
    "# mix cell types for each proportion set\n",
    "mix_celltypes_multiple_proportions(parquet_df=parquet_df,\n",
    "                                   total_reads_per_celltype=total_reads_per_celltype,\n",
    "                                   n=N, \n",
    "                                   cell_types=CELLTYPES, \n",
    "                                   cell_type_abridged_name=CELLTYPES_ABRIDGED_NAME, \n",
    "                                   total_reads_to_sample=TOTAL_READS_TO_SAMPLE, \n",
    "                                   list_of_proportions=PROPORTIONS, \n",
    "                                   seed=SEED, \n",
    "                                   result_path=RESULT_PATH, \n",
    "                                   verbose=False, \n",
    "                                   save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
