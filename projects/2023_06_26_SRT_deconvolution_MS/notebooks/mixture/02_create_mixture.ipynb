{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for creating mixtures from cell type parquet files created in notebook `01_combine_subjects_by_celltype.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# UPDATE HOME!\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark\"\n",
    "# THIS needs to be set-up before running the notebook\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.ui.showConsoleProgress\", \"True\")\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling in PySpark\n",
    "The `sample()` function takes fraction of reads to sample, not the number of reads to sample. \\\n",
    "We can compute the fraction from the total number of reads and the number of desired reads to sample. \\\n",
    "Mapping: `(N rows to sample) --> (F fraction to sample)`\n",
    "```\n",
    "N rows to sample = fraction * total reads\n",
    "fraction = N rows to sample / total reads\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixture_dir_name_string(list_celltype_name, list_proportion):\n",
    "    '''\n",
    "    Generate name for cell type given list of cell type name \n",
    "    ['B', 'CD4', 'CD8', 'NK', 'Mono', 'Neutro'] and \n",
    "    list of proportion np.array([0.5, 0.5, 0, 0, 0, 0]).\n",
    "    Output string: 'mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro]'\n",
    "    '''\n",
    "    list_proportion = [int(x) for x in PROPORTION * 100]\n",
    "    names = [f\"{b:02d}{a}\" if b < 10 else f\"{b}{a}\" for a, b in zip(list_celltype_name, list_proportion)]\n",
    "    dir_name = '_'.join(names)\n",
    "    return(dir_name)\n",
    "\n",
    "\n",
    "def mix_celltypes_helper(parquet_df, total_reads_per_celltype, cell_types, total_reads_to_sample, proportions, seed, parquet_path, result_path, verbose, save=False, itr=None):\n",
    "    ''' Mix reads from different cell types based on given proportion and total reads to sample.\n",
    "    Data is loaded once in mix_celltypes() to avoid loading dataframes repeatedly.\n",
    "    \n",
    "    Arguments:\n",
    "    paquet_df -- list of dataframes loaded in mix_celltypes()\n",
    "    total_reads_per_celltype -- calculated while reading in dataframe (nrow of each df)\n",
    "    cell_types -- list of cell type to mix\n",
    "    total_reads_to_sample -- integer representing the total number of reads to sample across all cell types\n",
    "    proportions -- list of proportions to sample for each cell type\n",
    "    seed -- seed for .sample()\n",
    "    parquet_path -- string of path to the directory with source cell type reads to mix from\n",
    "    result_path -- string of path to output parquet file\n",
    "    itr -- mixture iteration for creating multiple mixtures\n",
    "    \n",
    "    Output:\n",
    "    mixture -- pyspark.sql.dataframe.DataFrame\n",
    "    '''\n",
    "    \n",
    "    if verbose: print(f'--> seed: {seed}')\n",
    "    \n",
    "    # compute fraction to sample for each cell type (later convert to index)\n",
    "    n_reads_to_sample = proportions * total_reads_to_sample\n",
    "    sampling_fraction = n_reads_to_sample / total_reads_per_celltype\n",
    "    if verbose: print(f'Sampling fraction: {sampling_fraction}')\n",
    "    \n",
    "    # sample reads from each cell type\n",
    "    sampled_df = []\n",
    "    \n",
    "    if verbose: print('--> Sample rows for each cell type...')\n",
    "    for i in range(0, len(cell_types)):\n",
    "        if verbose: print(f'----------> Sampling cell type: {cell_types[i]}')\n",
    "        df = parquet_df[i]\n",
    "        frac = sampling_fraction[i]\n",
    "        df_sample = df.sample(False, frac, seed)\n",
    "        sampled_df.append(df_sample)\n",
    "        n_sampled = df_sample.count()\n",
    "        if verbose: print(f'----------> {n_sampled}')\n",
    "    \n",
    "    # combine reads\n",
    "    if verbose: print('--> Combining sampled reads into one dataframe...')\n",
    "    mixture = functools.reduce(DataFrame.union, sampled_df)\n",
    "    \n",
    "    if save:\n",
    "        # create file name \n",
    "        seed_string = str(int(seed))\n",
    "        celltype_string = '_'.join(cell_types)\n",
    "        proportion_str = [str(i) for i in proportions]\n",
    "        proportion_string = '_'.join(proportion_str)\n",
    "        mixture_itr = f'mix{itr}_'\n",
    "        file_name = mixture_itr + \\\n",
    "                    f'seed_{seed_string}' + \\\n",
    "                    '.parquet/'\n",
    "\n",
    "        if verbose: print('--> Saving parquet file...')\n",
    "        save_path = result_path + file_name\n",
    "        mixture.write.mode('overwrite').parquet(save_path)\n",
    "        if verbose: print(f'--> Saved to: {save_path}')\n",
    "    \n",
    "    return(mixture)\n",
    "\n",
    "\n",
    "def mix_celltypes(n, cell_types, total_reads_to_sample, proportions, seed, parquet_path, result_path, verbose, save=False):\n",
    "    '''Create n mixtures by mixing reads from different cell types based on given proportion and total reads to sample. \n",
    "    Calls mix_celltypes_helper() n times.\n",
    "    \n",
    "    Arguments:\n",
    "    n -- total number of mixtures to make\n",
    "    cell_types -- list of cell type to mix\n",
    "    total_reads_to_sample -- integer representing the total number of reads to sample across all cell types\n",
    "    proportions -- list of proportions to sample for each cell type\n",
    "    seed -- seed for .sample()\n",
    "    parquet_path -- string of path to the directory with source cell type reads to mix from\n",
    "    result_path -- string of path to output parquet file\n",
    "    \n",
    "    Output:\n",
    "    mixtures -- list(pyspark.sql.dataframe.DataFrame)\n",
    "    '''\n",
    "    \n",
    "    # Create output directory\n",
    "    dir_name = generate_mixture_dir_name_string(CELLTYPES_ABRIDGED_NAME, PROPORTION)\n",
    "    dir_name = 'mix_' + dir_name + '_seed_' + str(seed) + '/'\n",
    "    dir_path = result_path + dir_name\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        print(\"Folder %s created!\" % dir_path)\n",
    "    else:\n",
    "        print(\"Folder %s already exists\" % dir_path)\n",
    "        \n",
    "    # Generate seeds (between 0 and 1 million)\n",
    "    random.seed(seed)\n",
    "    seeds = [random.randint(0, 10**6) for _ in range(n)]\n",
    "    \n",
    "    # Only load data that has nonzero proportion to sample\n",
    "    cell_types = [a for a, b in zip(cell_types, proportions) if b != 0]\n",
    "    proportions = np.array([b for b in proportions if b != 0])\n",
    "    \n",
    "    # Load the parquet files for selected cell types & count rows\n",
    "    parquet_df = []\n",
    "    total_reads_per_celltype = []\n",
    "    \n",
    "    if verbose: print('--> Load parquet files and count rows...')\n",
    "    for cell_type in cell_types:\n",
    "        if verbose: print(f'----------> Loading cell type: {cell_type}')\n",
    "        df = spark.read.parquet(f'{parquet_path}collapsed_reads_{cell_type}/')\n",
    "        parquet_df.append(df)\n",
    "        total_reads_per_celltype.append(df.count())\n",
    "\n",
    "    total_reads_per_celltype = np.array(total_reads_per_celltype)\n",
    "    print(f'TOTAL_READS: {total_reads_per_celltype}')\n",
    "    # Create n mixtures\n",
    "    mixtures = []\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        \n",
    "        print(f'################ Creating mixture {i}... ################')\n",
    "        mixture = mix_celltypes_helper(parquet_df=parquet_df,\n",
    "                                       total_reads_per_celltype=total_reads_per_celltype,\n",
    "                                       cell_types=cell_types,\n",
    "                                       total_reads_to_sample=total_reads_to_sample, \n",
    "                                       proportions=proportions, \n",
    "                                       seed=seeds[i],\n",
    "                                       parquet_path=parquet_path,\n",
    "                                       result_path=dir_path,\n",
    "                                       save=save,\n",
    "                                       itr=i,\n",
    "                                       verbose=verbose)\n",
    "        mixtures.append(mixture)\n",
    "        print(' ')\n",
    "    \n",
    "    print(f'>>> Complete. <<<')\n",
    "    return(mixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/ already exists\n",
      "--> Load parquet files and count rows...\n",
      "----------> Loading cell type: Blueprint-B\n",
      "----------> Loading cell type: Blueprint-CD4\n",
      "TOTAL_READS: [2963964 1965191]\n",
      "################ Creating mixture 0... ################\n",
      "--> seed: 83723\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12479\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12431\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix0_seed_83723.parquet/\n",
      " \n",
      "################ Creating mixture 1... ################\n",
      "--> seed: 452891\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12309\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12351\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix1_seed_452891.parquet/\n",
      " \n",
      "################ Creating mixture 2... ################\n",
      "--> seed: 612330\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12528\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12434\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix2_seed_612330.parquet/\n",
      " \n",
      "################ Creating mixture 3... ################\n",
      "--> seed: 466724\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12252\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12358\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix3_seed_466724.parquet/\n",
      " \n",
      "################ Creating mixture 4... ################\n",
      "--> seed: 960318\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12290\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12333\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix4_seed_960318.parquet/\n",
      " \n",
      "################ Creating mixture 5... ################\n",
      "--> seed: 520710\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12515\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12517\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix5_seed_520710.parquet/\n",
      " \n",
      "################ Creating mixture 6... ################\n",
      "--> seed: 404706\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12445\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12400\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix6_seed_404706.parquet/\n",
      " \n",
      "################ Creating mixture 7... ################\n",
      "--> seed: 660471\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12565\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12505\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix7_seed_660471.parquet/\n",
      " \n",
      "################ Creating mixture 8... ################\n",
      "--> seed: 392926\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12447\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12557\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix8_seed_392926.parquet/\n",
      " \n",
      "################ Creating mixture 9... ################\n",
      "--> seed: 567724\n",
      "total_reads_to_sample: [2963964 1965191]\n",
      "Sampling fraction: [0.00421733 0.0063607 ]\n",
      "--> Sample rows for each cell type...\n",
      "----------> Sampling cell type: Blueprint-B\n",
      "----------> 12630\n",
      "----------> Sampling cell type: Blueprint-CD4\n",
      "----------> 12610\n",
      "--> Combining sampled reads into one dataframe...\n",
      "--> Saving parquet file...\n",
      "--> Saved to: /analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/mix_50B_50CD4_00CD8_00NK_00Mono_00Neutro_seed_888/mix9_seed_567724.parquet/\n",
      " \n",
      ">>> Complete. <<<\n",
      "CPU times: user 40.9 ms, sys: 28.5 ms, total: 69.4 ms\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1 mixture with N replicates\n",
    "\n",
    "N=10\n",
    "CELLTYPES = ['Blueprint-B', 'Blueprint-CD4', 'Blueprint-CD8', 'Blueprint-NK', 'Blueprint-Mono', 'Blueprint-Neutro']\n",
    "CELLTYPES_ABRIDGED_NAME = ['B', 'CD4', 'CD8', 'NK', 'Mono', 'Neutro']\n",
    "TOTAL_READS_TO_SAMPLE = 25000\n",
    "PROPORTION = np.array([0.5, 0.5, 0, 0, 0, 0])\n",
    "SEED = 888\n",
    "PARQUET_PATH = '/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture_source/'\n",
    "RESULT_PATH = '/analysis/gh-msun/projects/2023_06_26_SRT_deconvolution_MS/output/mixture/'\n",
    "\n",
    "test_mixtures = mix_celltypes(n=N,\n",
    "                             cell_types=CELLTYPES,\n",
    "                             total_reads_to_sample=TOTAL_READS_TO_SAMPLE, \n",
    "                             proportions=PROPORTION, \n",
    "                             seed=SEED,\n",
    "                             parquet_path=PARQUET_PATH,\n",
    "                             result_path=RESULT_PATH,\n",
    "                             save=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT sample_id)|\n",
      "+-------------------------+\n",
      "|                       31|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "test_mixtures[0].select(countDistinct('sample_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT region_id)|\n",
      "+-------------------------+\n",
      "|                     1655|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_mixtures[0].select(countDistinct('region_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+----------------+-------------+-------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|sample_id|molecule_id|  chr|number_molecules|cpg_index_min|cpg_index_max|          pat_string|           region_id|region_cpg_index_min|region_cpg_index_max|\n",
      "+---------+-----------+-----+----------------+-------------+-------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|ERS666930|  410443726|chr16|               1|     21773402|     21773416|     CCCCCCCCCCCCCCC|Loyfer2022_Prepri...|            21773392|            21773411|\n",
      "|ERS763500|  420348869|chr15|               1|     21491080|     21491103|CCCCCCCCCCCCCCCCC...|Umbilical_Endothe...|            21491086|            21491152|\n",
      "|ERS666930|  410292996|chr16|               1|     21756236|     21756247|        CCCCCCCCCCCC|Neuron_plus_Oligo...|            21756240|            21756264|\n",
      "|ERS666930|  410293129|chr16|               1|     21756263|     21756268|              TCCCCC|Neuron_plus_Oligo...|            21756240|            21756264|\n",
      "|ERS666927|  448174354|chr16|               1|     22802046|     22802051|              CCCCCC|Esophagus_Ep-chr1...|            22802024|            22802065|\n",
      "+---------+-----------+-----+----------------+-------------+-------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_mixtures[2].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
