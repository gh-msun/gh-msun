{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import IntegerType, LongType, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import udf, explode, broadcast, count, lit, length, col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Local paths\n",
    "ROOT_DIR = '/analysis/gh-msun/projects'\n",
    "PROJECT_SLUG = '2023_06_26_SRT_deconvolution_MS'\n",
    "PROJECT_DIR = ROOT_DIR + f'/{PROJECT_SLUG}'\n",
    "DATA_DIR = ROOT_DIR + f'/{PROJECT_SLUG}' + '/stage'\n",
    "SAMPLE_PATH = DATA_DIR + '/metadata/samples_wgbs.20230329.tsv'\n",
    "\n",
    "#--- parquet\n",
    "PARQUET_PATH_LIST_HG38 = [\n",
    "    '/analysis/hg38_20160816.pat.db_version.parquet'\n",
    "]\n",
    "\n",
    "#--- regions\n",
    "REGIONS = 'deconvolution_v2.v23_conv.with_cpg_index'\n",
    "\n",
    "REGION_BED_COLS = [\n",
    "    'region_chr', 'region_start', 'region_end', \n",
    "    'region_cpg_index_min', 'region_cpg_index_max', 'region_id'\n",
    "]\n",
    "\n",
    "REGION_PATH = (\n",
    "    PROJECT_DIR + '/stage/panel_data/{regions}.bed'\n",
    ").format(regions=REGIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset parquets to immune regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load regions we want to subset\n",
    "Load regions of interest to subset. e.g. The ATLAS dataframe contains BLUEPRINT immune regions only. The regions we want to subset to should be represented as a set of region id called `subset_region_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------- CHANGE HERE FOR DIFFERENT REGION SUBSET ----------------------\n",
    "# BLUEPRINT immune regions\n",
    "ATLAS_PATH = PROJECT_DIR + f'/output/deconv_inhouse_v2.atlas.tsv.gz'\n",
    "atlas = pd.read_csv(ATLAS_PATH, sep='\\t')\n",
    "subset_region_set = set(atlas.region_id)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# filter regions down to regions of interest\n",
    "region_df = pd.read_csv(REGION_PATH, sep='\\t', usecols=range(0, 6), names=REGION_BED_COLS)\n",
    "region_df_subset = region_df[region_df['region_id'].isin(subset_region_set)]\n",
    "region_df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_chr</th>\n",
       "      <th>region_start</th>\n",
       "      <th>region_end</th>\n",
       "      <th>region_cpg_index_min</th>\n",
       "      <th>region_cpg_index_max</th>\n",
       "      <th>region_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1114771</td>\n",
       "      <td>1114971</td>\n",
       "      <td>20117</td>\n",
       "      <td>20130</td>\n",
       "      <td>Immune_Broad_B-chr1:1114772-1114971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157450</td>\n",
       "      <td>1157720</td>\n",
       "      <td>21684</td>\n",
       "      <td>21704</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157451-1157720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1157879</td>\n",
       "      <td>1158277</td>\n",
       "      <td>21710</td>\n",
       "      <td>21727</td>\n",
       "      <td>Immune_Broad_NK-chr1:1157880-1158277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chr1</td>\n",
       "      <td>6341182</td>\n",
       "      <td>6341377</td>\n",
       "      <td>140667</td>\n",
       "      <td>140682</td>\n",
       "      <td>Immune_Broad_Eosi-chr1:6341183-6341377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chr1</td>\n",
       "      <td>9147788</td>\n",
       "      <td>9147871</td>\n",
       "      <td>188605</td>\n",
       "      <td>188609</td>\n",
       "      <td>Immune_Broad_Neutro-chr1:9147789-9147871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_chr  region_start  region_end  region_cpg_index_min  region_cpg_index_max                                 region_id\n",
       "0        chr1       1114771     1114971                 20117                 20130       Immune_Broad_B-chr1:1114772-1114971\n",
       "1        chr1       1157450     1157720                 21684                 21704      Immune_Broad_NK-chr1:1157451-1157720\n",
       "2        chr1       1157879     1158277                 21710                 21727      Immune_Broad_NK-chr1:1157880-1158277\n",
       "14       chr1       6341182     6341377                140667                140682    Immune_Broad_Eosi-chr1:6341183-6341377\n",
       "19       chr1       9147788     9147871                188605                188609  Immune_Broad_Neutro-chr1:9147789-9147871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parquet file as a pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## this works for PySpark v3.3.1 - only need to run this once\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages {aws_java},{aws_hadoop} pyspark-shell\".\\\n",
    "   format(aws_java=\"com.amazonaws:aws-java-sdk-bundle:1.11.271\",\n",
    "          aws_hadoop=\"org.apache.hadoop:hadoop-aws:3.1.2\")\n",
    "#####\n",
    "\n",
    "# UPDATE HOME!\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/mambaforge/envs/2023_06_26_SRT_deconvolution_MS/lib/python3.7/site-packages/pyspark\"\n",
    "# THIS needs to be set-up before running the notebook\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/temp\"\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.executor.instances\", \"2\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"2\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"64g\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "spark_conf.set(\"spark.parquet.filterPushdown\", \"true\")\n",
    "spark_conf.set(\"spark.local.dir\", \"/temp\")\n",
    "spark_conf.getAll()\n",
    "\n",
    "sc = SparkContext(conf=spark_conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_COLS = [\n",
    "    'sample_id', 'molecule_id', 'chr', 'number_molecules',\n",
    "    'cpg_index_min', 'cpg_index_max', 'pat_string'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sample_id: string (nullable = true)\n",
      " |-- molecule_id: string (nullable = true)\n",
      " |-- chr: string (nullable = true)\n",
      " |-- number_molecules: integer (nullable = true)\n",
      " |-- cpg_index_min: long (nullable = true)\n",
      " |-- cpg_index_max: long (nullable = true)\n",
      " |-- pat_string: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat_parquet_files = [spark.read.parquet(ifile).select(*PAT_COLS) for ifile in PARQUET_PATH_LIST_HG38]\n",
    "pat_hg38_ddf = functools.reduce(DataFrame.unionByName, pat_parquet_files)\n",
    "pat_hg38_ddf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "|sample_id|molecule_id| chr|number_molecules|cpg_index_min|cpg_index_max|          pat_string|\n",
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "|ERS337091|          2|chr1|               1|           17|           57|TTCTCCTTTCCCCCTTC...|\n",
      "|ERS337091|          1|chr1|               1|           19|           58|TTCCCCCTTCTCCTTTC...|\n",
      "|ERS337091|          3|chr1|               1|           99|          115|   CCCCCCCCCCCCCCCTT|\n",
      "|ERS337091|          6|chr1|               1|          101|          120|CCTCCCCCCCC....TTCTT|\n",
      "|ERS337091|          5|chr1|               1|          108|          118|         CCCCCCTCCTC|\n",
      "+---------+-----------+----+----------------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pat_hg38_ddf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe of reads that fall in the subsetted regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fragment_df_list = list()\n",
    "\n",
    "# for each region (row) get reads that fall into that region\n",
    "for _, row in region_df_subset.iterrows():\n",
    "    ov_ddf = pat_hg38_ddf.filter(col('cpg_index_min')<=row['region_cpg_index_max'])\\\n",
    "            .filter(col('cpg_index_max') >= row['region_cpg_index_min'])\\\n",
    "            .withColumn('region_id', lit(row['region_id']))\\\n",
    "            .withColumn('region_cpg_index_min', lit(row['region_cpg_index_min']))\\\n",
    "            .withColumn('region_cpg_index_max', lit(row['region_cpg_index_max']))\n",
    "    subset_fragment_df_list.append(ov_ddf)\n",
    "    \n",
    "# concatenate (union) the objects in list into one parquet file\n",
    "subset_parquet_df = subset_fragment_df_list[0]\n",
    "\n",
    "for df in subset_fragment_df_list[1:]:\n",
    "    subset_parquet_df = subset_parquet_df.unionByName(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+----------------+-------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|sample_id|molecule_id| chr|number_molecules|cpg_index_min|cpg_index_max|pat_string|           region_id|region_cpg_index_min|region_cpg_index_max|\n",
      "+---------+-----------+----+----------------+-------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|ERS337091|      61653|chr1|               1|        20108|        20117|CCCC..CCCC|Immune_Broad_B-ch...|               20117|               20130|\n",
      "|ERS337091|      61654|chr1|               1|        20111|        20117|   CCCCCCC|Immune_Broad_B-ch...|               20117|               20130|\n",
      "|ERS337091|      61655|chr1|               1|        20111|        20117|   CCCCCCC|Immune_Broad_B-ch...|               20117|               20130|\n",
      "|ERS337091|      61659|chr1|               1|        20111|        20117|   CCC.CCC|Immune_Broad_B-ch...|               20117|               20130|\n",
      "|ERS337091|      61663|chr1|               1|        20111|        20119| CCC.CCCCC|Immune_Broad_B-ch...|               20117|               20130|\n",
      "+---------+-----------+----+----------------+-------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset_parquet_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_count_by_sample = subset_parquet_df.groupBy('sample_id').count().orderBy('count')\n",
    "read_count_by_sample.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create parquet file for each cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>sample_group</th>\n",
       "      <th>age</th>\n",
       "      <th>source</th>\n",
       "      <th>stage_group</th>\n",
       "      <th>tumor_purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GSM5652274</td>\n",
       "      <td>Erythrocyte_progenitors</td>\n",
       "      <td>Erythrocyte progenitors</td>\n",
       "      <td>Eryth-prog</td>\n",
       "      <td>60.0</td>\n",
       "      <td>blueprint_loyfer2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GSM5652275</td>\n",
       "      <td>Erythrocyte_progenitors</td>\n",
       "      <td>Erythrocyte progenitors</td>\n",
       "      <td>Eryth-prog</td>\n",
       "      <td>53.0</td>\n",
       "      <td>blueprint_loyfer2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GSM5652276</td>\n",
       "      <td>Erythrocyte_progenitors</td>\n",
       "      <td>Erythrocyte progenitors</td>\n",
       "      <td>Eryth-prog</td>\n",
       "      <td>64.0</td>\n",
       "      <td>blueprint_loyfer2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ERS661049</td>\n",
       "      <td>BM030613</td>\n",
       "      <td>band form neutrophil</td>\n",
       "      <td>Blueprint-Neutro</td>\n",
       "      <td>65 - 70</td>\n",
       "      <td>blueprint_loyfer2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>ERS661048</td>\n",
       "      <td>BM030613</td>\n",
       "      <td>neutrophilic metamyelocyte</td>\n",
       "      <td>Blueprint-Neutro</td>\n",
       "      <td>65 - 70</td>\n",
       "      <td>blueprint_loyfer2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id               patient_id                   cell_type      sample_group      age                source stage_group  tumor_purity\n",
       "98   GSM5652274  Erythrocyte_progenitors     Erythrocyte progenitors        Eryth-prog     60.0  blueprint_loyfer2022         NaN           NaN\n",
       "99   GSM5652275  Erythrocyte_progenitors     Erythrocyte progenitors        Eryth-prog     53.0  blueprint_loyfer2022         NaN           NaN\n",
       "100  GSM5652276  Erythrocyte_progenitors     Erythrocyte progenitors        Eryth-prog     64.0  blueprint_loyfer2022         NaN           NaN\n",
       "211   ERS661049                 BM030613        band form neutrophil  Blueprint-Neutro  65 - 70  blueprint_loyfer2022         NaN           NaN\n",
       "212   ERS661048                 BM030613  neutrophilic metamyelocyte  Blueprint-Neutro  65 - 70  blueprint_loyfer2022         NaN           NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellType = [   \n",
    "    'Blueprint-B',\n",
    "    'Blueprint-CD4',\n",
    "    'Blueprint-CD8',\n",
    "    'Blueprint-NK',\n",
    "    'Blueprint-Dend',\n",
    "    'Blueprint-Macro',\n",
    "    'Blueprint-Mono',\n",
    "    'Blueprint-Eosi',\n",
    "    'Blueprint-Neutro',\n",
    "    'Blueprint-Eryth',\n",
    "    'Blueprint-Mega',\n",
    "    'Eryth-prog'\n",
    "]\n",
    "\n",
    "# map between sample and cell type\n",
    "sample_df = pd.read_csv(SAMPLE_PATH, sep='\\t')\n",
    "ridxs = (sample_df['source']=='blueprint_loyfer2022')\n",
    "ridxs &= sample_df['sample_group'].isin(cellType)\n",
    "ref_sample_df = sample_df[ridxs].copy()\n",
    "ref_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_group\n",
       "Blueprint-B         17\n",
       "Blueprint-CD4       14\n",
       "Blueprint-CD8       10\n",
       "Blueprint-Dend       2\n",
       "Blueprint-Eosi       2\n",
       "Blueprint-Eryth      2\n",
       "Blueprint-Macro     18\n",
       "Blueprint-Mega       2\n",
       "Blueprint-Mono       8\n",
       "Blueprint-NK         4\n",
       "Blueprint-Neutro    21\n",
       "Eryth-prog           3\n",
       "Name: sample_id, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many samples do each cell type have?\n",
    "ref_sample_df.groupby('sample_group').sample_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try saving parquet file for just one celltype and time it \n",
    "# need to count the number of molecules per region by cell type per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELLTYPE = 'Blueprint-B'\n",
    "samples_by_celltype = list(ref_sample_df[ref_sample_df['sample_group'] == CELLTYPE]['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ERS666927',\n",
       " 'ERS337605',\n",
       " 'ERS337607',\n",
       " 'ERS666931',\n",
       " 'ERS214672',\n",
       " 'ERS214675',\n",
       " 'ERS222206',\n",
       " 'ERS222208',\n",
       " 'ERS568736',\n",
       " 'ERS666930',\n",
       " 'ERS666929',\n",
       " 'ERS822885',\n",
       " 'ERS1022343',\n",
       " 'ERS222266',\n",
       " 'ERS523616',\n",
       " 'ERS523625',\n",
       " 'ERS763500']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_celltype = subset_parquet_df.filter((col('sample_id')).isin(samples_by_celltype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_celltype.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
